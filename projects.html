<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <title>Personal Projects - Filippo Navarra</title>

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    >
    <link rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
      integrity="sha512-iecdLmaskl7CVkqkXNQ/ZH/XLlvWZOJyj7Yy7tcenmpD1ypASozpmT/E0iPtmFIB46ZmdtAc9eNBvH0H/ZpiBw=="
      crossorigin="anonymous" referrerpolicy="no-referrer" />

    <style>
        :root {
            --accent: #667eea;
            --accent-hover: #5567c9;
            --bg-grad-a: #f5f7fa;
            --bg-grad-b: #c3cfe2;
            --text-primary: #1a202c;
            --text-secondary: #2d3748;
            --border-subtle: #e2e8f0;
            --shadow-medium: 0 10px 25px rgba(0,0,0,0.15);
            --focus-ring: 0 0 0 3px rgba(102,126,234,0.5);
        }

        * { margin:0; padding:0; box-sizing:border-box; }
        body {
            font-family: 'Inter', system-ui, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: var(--text-secondary);
            background: linear-gradient(135deg, var(--bg-grad-a) 0%, var(--bg-grad-b) 100%);
            min-height: 100vh;
        }

        nav {
            position: fixed; top:0; left:0; right:0;
            background: rgba(250,250,250,0.85);
            backdrop-filter: blur(12px);
            border-bottom: 1px solid var(--border-subtle);
            z-index: 1000;
            transition: all .3s ease;
        }
        nav .nav-content {
            display:flex; justify-content:space-between; align-items:center;
            height:70px; max-width:1200px; margin:0 auto; padding:0 2rem;
        }
        nav .logo {
            font-size:1.5rem; font-weight:600; color:var(--text-primary);
            text-decoration:none; transition:opacity .2s ease;
        }
        nav .logo:hover { opacity:.8; }
        nav .nav-links { display:flex; align-items:center; gap:2rem; }
        nav .nav-links a {
            color:var(--text-secondary); text-decoration:none; font-weight:500;
            transition:all .2s ease; display:flex; align-items:center; gap:.5rem;
            padding:.5rem 0; position:relative;
        }
        nav .nav-links a:hover { color:var(--accent); transform:translateY(-1px); }
        nav .nav-links a.cta {
            background: var(--accent); color:#000; padding:.6rem 1.2rem;
            border-radius:50px; transition:all .2s ease;
        }
        nav .nav-links a.cta:hover {
            background: var(--accent-hover); transform:translateY(-2px);
            box-shadow: var(--shadow-medium);
        }

        .page-wrapper {
            max-width:1200px;
            margin:90px auto 40px;
            padding:0 2rem 60px;
        }

        .header {
            background: linear-gradient(135deg, #667eea 20%, #764ba2 80%);
            color:#fff; padding:70px 50px;
            border-radius:20px;
            box-shadow:0 15px 40px rgba(0,0,0,.12);
            position:relative;
            overflow:hidden;
        }
        .header::after {
            content:'';
            position:absolute;
            inset:0;
            background: radial-gradient(circle at 70% 30%, rgba(255,255,255,0.15), transparent 70%);
            pointer-events:none;
        }
        .header h1 {
            font-size:2.6rem; margin-bottom:12px; font-weight:700;
            letter-spacing:-.5px;
        }
        .header p {
            font-size:1.05rem; opacity:.95; max-width:600px;
        }

        /* Flashcard Grid */
        .flashcards {
            margin-top:50px;
            display:grid;
            gap:30px;
            grid-template-columns: repeat(auto-fill, minmax(260px, 1fr));
        }
        .flashcard {
            background:#fff;
            border:2px solid #edf2f7;
            border-radius:18px;
            padding:22px 22px 26px;
            position:relative;
            display:flex;
            flex-direction:column;
            gap:14px;
            cursor:pointer;
            transition: box-shadow .35s, transform .25s, border-color .25s;
            box-shadow:0 4px 14px rgba(0,0,0,.06);
        }
        .flashcard:hover {
            transform: translateY(-6px);
            box-shadow:0 12px 28px -4px rgba(102,126,234,.35);
            border-color: var(--accent);
        }
        .flashcard:focus-visible {
            outline:none;
            box-shadow: var(--focus-ring), 0 12px 28px -4px rgba(102,126,234,.35);
            border-color: var(--accent);
        }
        .flashcard h3 {
            font-size:1.2rem;
            color:#2d3748;
            font-weight:600;
            display:flex;
            align-items:center;
            gap:.6rem;
        }
        .flashcard h3 .icon {
            display:inline-flex;
            width:36px; height:36px;
            border-radius:12px;
            align-items:center; justify-content:center;
            background:linear-gradient(135deg,#667eea,#764ba2);
            color:#fff; font-size:1rem;
            box-shadow:0 4px 10px rgba(118,75,162,.4);
        }
        .flashcard p {
            font-size:.88rem;
            color:#4a5568;
            line-height:1.4;
        }
        .pill-row {
            display:flex; flex-wrap:wrap; gap:8px;
        }
        .pill {
            background:linear-gradient(135deg,#667eea,#764ba2);
            color:#fff; font-size:.65rem; font-weight:500;
            padding:5px 10px;
            border-radius:30px;
            letter-spacing:.5px;
            box-shadow:0 3px 8px rgba(102,126,234,.35);
        }
        .flashcard .cta-inline {
            margin-top:auto;
            font-size:.75rem;
            font-weight:600;
            display:inline-flex;
            align-items:center;
            gap:6px;
            color:var(--accent);
            background: #eef2ff;
            padding:8px 12px;
            border-radius:12px;
            transition:background .25s, color .25s;
        }
        .flashcard:hover .cta-inline {
            background: var(--accent);
            color:#fff;
        }

        /* Detail Overlay */
        .detail-overlay {
            position:fixed;
            inset:0;
            background:rgba(26,32,44,.55);
            backdrop-filter: blur(12px);
            display:none;
            z-index:1100;
            overflow-y:auto;
            padding:70px 24px 120px;
        }
        .detail-inner {
            max-width:1000px;
            margin:0 auto;
            background:#fff;
            border-radius:22px;
            box-shadow:0 25px 55px -10px rgba(0,0,0,.35);
            overflow:hidden;
            animation:fadeSlide .45s cubic-bezier(.16,.8,.3,1);
        }
        @keyframes fadeSlide {
            from { opacity:0; transform:translateY(40px) scale(.96); }
            to   { opacity:1; transform:translateY(0) scale(1); }
        }
        .detail-header {
            background:linear-gradient(135deg,#667eea 20%, #764ba2 80%);
            color:#fff;
            padding:60px 55px 70px;
            position:relative;
        }
        .detail-header h2 {
            font-size:2.2rem;
            margin-bottom:12px;
            font-weight:700;
            letter-spacing:-.5px;
        }
        .detail-header p {
            max-width:620px;
            font-size:1rem;
            opacity:.96;
        }
        .detail-body {
            padding:50px 55px 60px;
            background:#fff;
        }

        /* Re-use existing detailed styles (scoped) */
        .detail-body .project-meta { display:flex; gap:15px; margin-bottom:28px; flex-wrap:wrap; }
        .detail-body .tag {
            background:linear-gradient(135deg,#667eea,#764ba2);
            color:#fff; padding:6px 16px; border-radius:20px;
            font-size:.75rem; font-weight:500;
            box-shadow:0 4px 10px rgba(102,126,234,.35);
        }
        .detail-body .section { margin-bottom:40px; }
        .detail-body .section-title {
            font-size:1.25rem; color:#667eea; margin-bottom:16px;
            font-weight:600; display:flex; align-items:center; gap:10px;
        }
        .detail-body .section-title::before { content:'‚ñ∂'; font-size:.7em; }
        .detail-body .section-content {
            color:#4a5568; line-height:1.75; margin-bottom:15px; font-size:.95rem;
        }
        .highlight-box, .insight-box {
            border-radius:14px; margin:28px 0;
            padding:24px 26px;
            line-height:1.6;
            font-size:.92rem;
        }
        .highlight-box {
            background:linear-gradient(135deg,#f6f8fb 0%, #e9ecef 100%);
            border-left:5px solid #667eea;
        }
        .insight-box {
            background:linear-gradient(135deg,#fff5f5 0%, #fed7d7 100%);
            border-left:5px solid #fc8181;
        }
        .insight-box strong { color:#c53030; }
        .technical-details {
            display:grid;
            grid-template-columns: repeat(auto-fit,minmax(220px,1fr));
            gap:20px; margin:25px 0;
        }
        .detail-card {
            background:#fff; border:2px solid #e2e8f0;
            border-radius:14px; padding:18px 20px;
            transition:transform .3s, box-shadow .3s, border-color .3s;
        }
        .detail-card:hover {
            transform:translateY(-5px);
            box-shadow:0 10px 25px rgba(102,126,234,.25);
            border-color:#667eea;
        }
        .detail-card h4 { color:#667eea; margin-bottom:10px; font-size:1.05rem; }
        .detail-card p { color:#4a5568; font-size:.88rem; line-height:1.5; }

        .code-snippet {
            background:#2d3748; color:#e2e8f0;
            padding:20px; border-radius:12px;
            font-family:'Courier New', monospace;
            font-size:.82rem; overflow-x:auto;
            margin:18px 0;
        }

        .github-link {
            display:inline-flex; align-items:center; gap:10px;
            background:#2d3748; color:#fff;
            padding:14px 26px; border-radius:12px;
            text-decoration:none; font-weight:500;
            transition:transform .3s, box-shadow .3s;
            margin-top:10px;
        }
        .github-link:hover {
            transform:translateY(-2px);
            box-shadow:0 5px 18px rgba(0,0,0,.35);
        }

        .close-btn {
            position:absolute;
            top:18px; right:18px;
            background:rgba(255,255,255,.18);
            backdrop-filter: blur(6px);
            border:2px solid rgba(255,255,255,.35);
            color:#fff;
            width:44px; height:44px;
            display:flex; align-items:center; justify-content:center;
            border-radius:14px;
            font-size:1.1rem;
            cursor:pointer;
            transition:background .3s, transform .25s;
        }
        .close-btn:hover {
            background:rgba(255,255,255,.35);
            transform:scale(1.05);
        }
        .close-btn:focus-visible {
            outline:none;
            box-shadow: var(--focus-ring);
        }

        /* Hide source template (progressive enhancement) */
        .detail-template { display:none; }

        /* Added styles for Italian Forward Report */
        .figure-block {
            margin:30px 0;
            text-align:center;
        }
        .figure-block img {
            max-width:100%;
            height:auto;
            border:2px solid #e2e8f0;
            border-radius:12px;
            box-shadow:0 6px 18px rgba(0,0,0,.08);
        }
        .figure-block figcaption {
            font-size:.75rem;
            color:#4a5568;
            margin-top:8px;
            font-style:italic;
        }
        .metrics-table-wrapper {
            overflow-x:auto;
            margin:24px 0 34px;
        }
        table.model-metrics {
            border-collapse:collapse;
            width:100%;
            font-size:.85rem;
            background:#fff;
        }
        table.model-metrics th, table.model-metrics td {
            border:1px solid #e2e8f0;
            padding:10px 12px;
            text-align:left;
        }
        table.model-metrics th {
            background:linear-gradient(135deg,#667eea,#764ba2);
            color:#fff;
            font-weight:600;
            letter-spacing:.3px;
        }
        table.model-metrics tbody tr:nth-child(even) {
            background:#f7fafc;
        }
        .badge-row {
            display:flex;
            flex-wrap:wrap;
            gap:10px;
            margin:12px 0 4px;
        }
        .perf-badge {
            background:#eef2ff;
            color:#2d3748;
            padding:6px 12px;
            border-radius:18px;
            font-size:.7rem;
            font-weight:600;
            letter-spacing:.5px;
            border:1px solid #c3d1ff;
        }
        .perf-badge.negative { background:#fff5f5; border-color:#feb2b2; }
        .perf-badge.positive { background:#f0fff4; border-color:#9ae6b4; }
        .callout-note {
            background:linear-gradient(135deg,#fffbea,#fff5d1);
            border-left:5px solid #d69e2e;
            padding:18px 20px;
            border-radius:14px;
            font-size:.8rem;
            color:#744210;
            margin:26px 0;
        }

        @media (max-width: 780px) {
            .header { padding:60px 36px; }
            .header h1 { font-size:2.2rem; }
            .detail-header { padding:50px 40px 60px; }
            .detail-body { padding:40px 38px 55px; }
            .flashcard { padding:20px 20px 24px; }
        }
    </style>
</head>
<body>
    <nav id="navbar">
        <div class="nav-content">
            <a href="#" class="logo">Filippo Navarra</a>
            <div class="nav-links">
                <a href="index.html"><i class="fa-solid fa-code"></i><span>Main</span></a>
                <a href="https://github.com/Filippo2605" target="_blank" rel="noopener noreferrer">
                    <i class="fa-brands fa-github"></i><span>Github</span>
                </a>
                <a href="https://www.linkedin.com/in/filippo-navarra-b7a72a28b/"
                   target="_blank" rel="noopener noreferrer">
                    <i class="fa-brands fa-linkedin"></i><span>LinkedIn</span>
                </a>
                <a href="mailto:filipponavarra224@gmail.com" class="cta">
                    <i class="fa-solid fa-envelope"></i><span>Email</span>
                </a>
            </div>
        </div>
    </nav>

    <main class="page-wrapper">
        <section class="header" aria-labelledby="projects-heading">
            <h1 id="projects-heading">Personal Projects</h1>
            <p>Exploring data, building solutions, and learning through experimentation</p>
        </section>

        <!-- Flashcards Section -->
        <section class="flashcards" aria-label="Project flashcards">
            <!-- Card: LinkedIn Comment Scraper -->
            <article class="flashcard"
                     tabindex="0"
                     role="button"
                     aria-haspopup="dialog"
                     aria-controls="project-detail"
                     data-project="linkedin-scraper">
                <h3><span class="icon"><i class="fa-solid fa-comments"></i></span>LinkedIn Comment Scraper</h3>
                <div class="pill-row">
                    <span class="pill">Python</span>
                    <span class="pill">Selenium</span>
                    <span class="pill">Automation</span>
                    <span class="pill">Web Scraping</span>
                </div>
                <p>Automation pipeline that loads and preserves dynamic LinkedIn post comment threads for downstream NLP & analytics.</p>
                <span class="cta-inline">Open details <i class="fa-solid fa-arrow-right"></i></span>
            </article>

            <!-- Card: Italian Forward Report -->
            <article class="flashcard"
                     tabindex="0"
                     role="button"
                     aria-haspopup="dialog"
                     aria-controls="project-detail"
                     data-project="italian-forward-report">
                <h3><span class="icon"><i class="fa-solid fa-futbol"></i></span>Italian Forward Report 2024</h3>
                <div class="pill-row">
                    <span class="pill">Python</span>
                    <span class="pill">R</span>
                    <span class="pill">PCA</span>
                    <span class="pill">Clustering</span>
                    <span class="pill">CART</span>
                    <span class="pill">Random Forest</span>
                </div>
                <p>Data-driven evaluation of historical & current Italian national team forwards to project goal contribution for UEFA Euro 2024.</p>
                <span class="cta-inline">Open details <i class="fa-solid fa-arrow-right"></i></span>
            </article>
            <!-- Card: Mental Health in Tech -->
             <article class="flashcard"
                tabindex="0"
                role="button"
                aria-haspopup="dialog"
                aria-controls="project-detail"
                data-project="third-project">
        <h3><span class="icon"><i class="fa-solid fa-heart-pulse"></i></span>Mental Health in Tech: OSMI 2016</h3>
        <div class="pill-row">
            <span class="pill">Python</span>
            <span class="pill">EDA</span>
            <span class="pill">Modeling</span>
            <span class="pill">HR Analytics</span>
        </div>
        <p>Cleaned and analyzed OSMI 2016 to reveal how workplace culture and resources relate to mental health outcomes.</p>
        <span class="cta-inline">Open details <i class="fa-solid fa-arrow-right"></i></span>
        </article>

        <!-- Card: Pandoro Gate NLP Analysis -->
        <article class="flashcard"
                tabindex="0"
                role="button"
                aria-haspopup="dialog"
                aria-controls="project-detail"
                data-project="pandoro-gate-nlp">
            <h3><span class="icon"><i class="fa-solid fa-magnifying-glass-chart"></i></span>Pandoro Gate NLP Analysis</h3>
            <div class="pill-row">
                <span class="pill">Python</span>
                <span class="pill">NLP</span>
                <span class="pill">Sentiment Analysis</span>
                <span class="pill">Topic Modeling</span>
            </div>
            <p>In-depth analysis of public opinion on social media surrounding the "Pandoro Gate" scandal using NLP techniques.</p>
            <span class="cta-inline">Open details <i class="fa-solid fa-arrow-right"></i></span>
        </article>

        <!-- Card: Customer Churn Prediction -->
        <article class="flashcard"
                 tabindex="0"
                 role="button"
                 aria-haspopup="dialog"
                 aria-controls="project-detail"
                 data-project="customer-churn">
            <h3><span class="icon"><i class="fa-solid fa-user-slash"></i></span>Customer Churn Prediction</h3>
            <div class="pill-row">
                <span class="pill">Python</span>
                <span class="pill">Scikit-learn</span>
                <span class="pill">Classification</span>
                <span class="pill">EDA</span>
            </div>
            <p>Developed a model to predict telecom customer churn, identifying key drivers and enabling proactive retention strategies.</p>
            <span class="cta-inline">Open details <i class="fa-solid fa-arrow-right"></i></span>
        </article>

        <!-- Card: Automated Journalism -->
        <article class="flashcard"
                 tabindex="0"
                 role="button"
                 aria-haspopup="dialog"
                 aria-controls="project-detail"
                 data-project="automated-journalism">
            <h3><span class="icon"><i class="fa-solid fa-newspaper"></i></span>Automated Journalism</h3>
            <div class="pill-row">
                <span class="pill">Python</span>
                <span class="pill">LangChain</span>
                <span class="pill">LLMs</span>
                <span class="pill">Streamlit</span>
            </div>
            <p>AI-powered pipeline to generate journalistic articles from structured data, automating repetitive writing tasks.</p>
            <span class="cta-inline">Open details <i class="fa-solid fa-arrow-right"></i></span>
        </article>
        </section>
    <!-- Hidden template holding full project HTML (original content preserved) -->
    <template id="linkedin-scraper-template" class="detail-template">
        <header class="detail-header">
            <h2 id="detailTitle">LinkedIn Comment Scraper</h2>
            <p>Automated extraction of dynamic LinkedIn comment threads for structured analysis and downstream NLP enrichment.</p>
        </header>
        <div class="detail-body">
            <div class="project-meta">
                <span class="tag">Python</span>
                <span class="tag">Selenium</span>
                <span class="tag">Web Scraping</span>
                <span class="tag">Automation</span>
            </div>

            <div class="section">
                <p class="section-content">
                    In a world where social media conversations hold immense value for understanding public sentiment, engagement patterns, and community dynamics, I built a tool that bridges the gap between LinkedIn's professional discourse and actionable data insights. This project automates the extraction of comments from LinkedIn posts, transforming ephemeral conversations into structured data ready for analysis.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">The Challenge</h3>
                <p class="section-content">
                    LinkedIn's dynamic, JavaScript-heavy interface presents unique challenges for data extraction. Unlike static websites, comments load progressively, requiring interaction with the page to reveal the full conversation. The platform's authentication layer and anti-scraping measures add another dimension of complexity. The goal was clear: create a reliable, automated pipeline that could navigate these obstacles while respecting the platform's structure.
                </p>
            </div>

            <div class="highlight-box">
                <strong>Key Insight:</strong> Modern web scraping isn't just about parsing HTML‚Äîit's about simulating human behavior, understanding asynchronous content loading, and building robust systems that can handle the unpredictable nature of dynamic web applications.
            </div>

            <div class="section">
                <h3 class="section-title">Technical Deep Dive</h3>
                <div class="technical-details">
                    <div class="detail-card">
                        <h4>üîê Authentication Layer</h4>
                        <p>Implemented secure credential management with automated login flow using Selenium WebDriver, handling LinkedIn's authentication challenge while maintaining session persistence.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üîÑ Dynamic Content Loading</h4>
                        <p>Engineered an intelligent pagination system that detects and clicks "Load More" buttons recursively, ensuring complete comment extraction regardless of thread length.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üéØ Smart Element Selection</h4>
                        <p>Utilized XPath and CSS selectors to reliably target comment sorting options, switching to "Most Recent" view for chronological data organization.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üíæ Data Preservation</h4>
                        <p>Captured the complete rendered HTML state, creating a snapshot that preserves all loaded comments for offline processing with BeautifulSoup.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h3 class="section-title">The Architecture</h3>
                <p class="section-content">
                    The scraper follows a three-stage pipeline architecture:
                </p>
                <div class="highlight-box">
                    <strong>Stage 1: Initialization & Authentication</strong><br>
                    The WebDriver initializes with Microsoft Edge, navigating to LinkedIn's login portal. Credentials are securely injected, and the system waits for successful authentication before proceeding.
                    <br><br>
                    <strong>Stage 2: Navigation & Dynamic Loading</strong><br>
                    Once authenticated, the scraper navigates to the target post URL. It intelligently identifies and interacts with comment sorting menus, then enters a recursive loop to load all hidden comments.
                    <br><br>
                    <strong>Stage 3: Extraction & Persistence</strong><br>
                    With all comments visible, the complete page source is captured and saved as HTML. This decouples scraping from parsing, allowing for flexible downstream analysis.
                </div>
            </div>

            <div class="section">
                <h3 class="section-title">Code Walkthrough</h3>
                <p class="section-content">
                    Here's how the comment loading mechanism works‚Äîthe heart of the automation:
                </p>
                <div class="code-snippet">
<pre><code>
# Recursive comment loading algorithm
while True:
    try:
        load_button = driver.find_element(
            By.XPATH,
            "//button[contains(@aria-label, 'Load more')]"
        )
        driver.execute_script(
            "arguments[0].scrollIntoView();",
            load_button
        )
        load_button.click()
        time.sleep(2)  # Allow content to render
    except:
        break  # No more comments to load
</code></pre>
                </div>
                <p class="section-content">
                    This elegant loop continues until the "Load more" button disappears, indicating all comments are visible. The scroll behavior ensures elements are in the viewport before interaction, preventing common Selenium exceptions.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">Beyond Basic Scraping</h3>
                <p class="section-content">
                    What makes this project particularly interesting is its extensibility. The saved HTML serves as a foundation for sophisticated analysis:
                </p>
                <ul class="section-content" style="margin-left:20px;">
                    <li><strong>Sentiment Analysis:</strong> Feed comment text into NLP models to gauge audience reaction to posts</li>
                    <li><strong>Network Mapping:</strong> Extract commenter profiles to build engagement networks and identify key influencers</li>
                    <li><strong>Temporal Analysis:</strong> Study comment velocity and timing to understand optimal posting schedules</li>
                    <li><strong>Content Strategy:</strong> Analyze which topics generate the most meaningful discussions</li>
                </ul>
            </div>

            <div class="insight-box">
                <strong>Ethical Consideration:</strong> This project exists in the educational space, designed to understand web automation and data extraction techniques. Real-world applications must respect LinkedIn's Terms of Service, rate limiting, and user privacy. The goal is learning, not exploitation.
            </div>

            <div class="section">
                <h3 class="section-title">What I Learned</h3>
                <p class="section-content">
                    Building this scraper reinforced several key principles that extend beyond just technical implementation. I learned that effective web scraping is as much about understanding human-computer interaction patterns as it is about code. The challenges of timing, state management, and error handling in a dynamic environment taught me to think in terms of systems resilience rather than just functionality.
                </p>
                <p class="section-content">
                    Perhaps most importantly, this project highlighted the importance of separating concerns‚Äîkeeping scraping logic distinct from parsing logic creates more maintainable, flexible systems that can adapt as websites evolve.
                </p>
            </div>

            <a href="https://github.com/Filippo2605/Scraping-Linkedin-Post-comments"
               class="github-link" target="_blank" rel="noopener">
               <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true">
                   <path d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"/>
               </svg>
               View Project on GitHub
            </a>
        </div>
    </template>

    <!-- New template: Italian Forward Report -->
    <template id="italian-forward-report-template" class="detail-template">
        <header class="detail-header">
            <h2 id="detailTitle">Italian Forward Report ‚Äì UEFA Euro 2024 Projection</h2>
            <p>Integrated scraping, multivariate reduction, clustering, and predictive modeling (CART & Random Forest) to estimate national-team goal potential for current Italian forwards.</p>
        </header>
        <div class="detail-body">
            <div class="project-meta">
                <span class="tag">Python</span>
                <span class="tag">R</span>
                <span class="tag">Web Scraping</span>
                <span class="tag">PCA</span>
                <span class="tag">Clustering</span>
                <span class="tag">CART</span>
                <span class="tag">Random Forest</span>
                <span class="tag">Sports Analytics</span>
            </div>

            <!-- Introduction -->
            <div class="section">
                <h3 class="section-title">Introduction</h3>
                <p class="section-content">
                    Aim: predict which current Italian forwards would be most effective if called for Euro 2024 using historical national-team forward data from Transfermarkt.
                    Target variable: National Team Goals. Players classified by comparing predicted goals (y<sub>pred</sub>) vs actual (y<sub>true</sub>):
                    <span class="perf-badge positive">Overperforming: y_true > y_pred</span>
                    <span class="perf-badge negative">Underperforming: y_true &lt; y_pred</span>
                </p>
                <p class="section-content">
                    Pipeline phases: Scraping (Python) ‚Üí PCA ‚Üí Clustering ‚Üí CART ‚Üí Random Forest ‚Üí Conclusion (R for analytical phases).
                    Assumption: Goals as proxy for overall forward contribution (simplification ‚Äî excludes pressing or creation effects).
                </p>
            </div>

            <!-- Scraping Data -->
            <div class="section">
                <h3 class="section-title">Data Acquisition (Transfermarkt Scrape)</h3>
                <p class="section-content">
                    Source chosen for depth of historical coverage (Meazza, Piola, etc.). Steps: paginated profile harvesting (requests + BeautifulSoup), name sanitization (regex), per-player stat extraction (appearances, goals, assists, substitutions, cards, penalties, per-minute metrics), results persisted to players.csv and player_stats.csv. Errors logged; missing structured values handled gracefully.
                </p>
                <div class="highlight-box">
                    <strong>Dataset Variables (20):</strong><br>
                    Player Name; Total Appearances; Goals; Assists; Substituted In; Substituted Out; Yellow Card; Red Card; Goals from Penalty; Goals per Minutes; National Team Appearances; National Team Goals; National Team Assists; Substituted In (NT); Substituted Out (NT); Yellow Card (NT); Red Card (NT); Goals from Penalty (NT); Goals per Minutes (NT); Minutes Played (NT).
                </div>
            </div>

            <!-- PCA -->
            <div class="section">
                <h3 class="section-title">Principal Component Analysis (PCA)</h3>
                <div class="badge-row">
                    <span class="perf-badge">PC1 35.16%</span>
                    <span class="perf-badge">PC2 11.59%</span>
                    <span class="perf-badge">PC1‚Äì2 46.75%</span>
                    <span class="perf-badge">Focus PCs: 1‚Äì3</span>
                </div>
                <p class="section-content">
                    FactoMineR + factoextra used after numeric cleaning (removing non-digit characters from rate features). PC1 dominated variance (usage & productivity blend); PC2 separated complementary contribution aspects. Outlier profile: Francesco Totti. Strong correlation observed: Minutes Played (NT) ‚Üî Goals per Minutes (indicative of sustained efficiency).
                </p>
                <figure class="figure-block">
                    <img src="PCA.png" alt="PCA individuals plot">
                    <figcaption>PCA Individuals ‚Äì distribution & notable outliers</figcaption>
                </figure>
                <figure class="figure-block">
                    <img src="pca2.png" alt="PCA variables plot">
                    <figcaption>PCA Variables ‚Äì correlated performance metrics</figcaption>
                </figure>
                <figure class="figure-block">
                    <img src="screeplot.png" alt="Screeplot eigenvalues">
                    <figcaption>Screeplot ‚Äì retained components justification</figcaption>
                </figure>
            </div>

            <!-- Clustering -->
            <div class="section">
                <h3 class="section-title">Clustering Player Archetypes</h3>
                <p class="section-content">
                    K-means applied to standardized numeric performance metrics (Elbow + Silhouette for k selection). Distinct clusters reveal archetypes of efficiency, volume, and hybrid contribution. Correlation heatmap clarifies intra-cluster variable influence.
                </p>
                <figure class="figure-block">
                    <img src="elbow.png" alt="Elbow method plot">
                    <figcaption>Elbow Method ‚Äì diminishing WCSS returns</figcaption>
                </figure>
                <figure class="figure-block">
                    <img src="silhoutte.png" alt="Silhouette method plot">
                    <figcaption>Silhouette ‚Äì average separation quality</figcaption>
                </figure>
                <figure class="figure-block">
                    <img src="cluster.png" alt="Cluster visualization">
                    <figcaption>Cluster Projection ‚Äì player grouping in reduced space</figcaption>
                </figure>
                <figure class="figure-block">
                    <img src="heatmap.png" alt="Correlation heatmap">
                    <figcaption>Correlation Matrix ‚Äì relationships among metrics</figcaption>
                </figure>
                <div class="highlight-box">
                    <strong>Next Enhancement:</strong> Label clusters semantically (e.g., ‚ÄúHigh-Usage Finishers‚Äù, ‚ÄúEfficient Impact Subs‚Äù) once descriptive summaries finalized.
                </div>
            </div>

            <!-- CART -->
            <div class="section">
                <h3 class="section-title">CART Modeling</h3>
                <p class="section-content">
                    rpart regression tree (method="anova") trained on historical forwards. Predictors: all numeric performance metrics; target: National Team Goals. Tree visualized with rpart.plot for interpretability (split hierarchy: usage ‚Üí efficiency ‚Üí discipline).
                </p>
                <div class="badge-row">
                    <span class="perf-badge negative">MAE 4.91</span>
                    <span class="perf-badge negative">MSE 53.00</span>
                    <span class="perf-badge negative">R¬≤ -0.69</span>
                </div>
                <p class="section-content">
                    Indicates poor generalization‚Äîhigh variance not captured by simple hierarchical splits. Overperformers vs model expectations (CART perspective): Immobile, Balotelli, Berardi, Colombo, El Shaarawy.
                </p>
            </div>

            <!-- Random Forest -->
            <div class="section">
                <h3 class="section-title">Random Forest Ensemble</h3>
                <p class="section-content">
                    randomForest (ntree=100) improved stability via bagged decorrelated trees. Predictions rounded to nearest integer to reflect discrete goal totals.
                </p>
                <div class="badge-row">
                    <span class="perf-badge">MAE 3.48</span>
                    <span class="perf-badge">MSE 23.40</span>
                    <span class="perf-badge">R¬≤ 0.25</span>
                </div>
                <p class="section-content">
                    Overperformers (Random Forest narrative): Pessina, Frattesi, Iemmello.<br>
                </p>
            </div>

            <!-- Model Performance Table -->
            <div class="section">
                <h3 class="section-title">Model Performance Summary</h3>
                <div class="metrics-table-wrapper">
                    <table class="model-metrics" aria-describedby="metrics-note">
                        <thead>
                            <tr>
                                <th>Metric</th>
                                <th>CART</th>
                                <th>Random Forest</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>MAE</td>
                                <td>4.91</td>
                                <td>3.48*</td>
                            </tr>
                            <tr>
                                <td>MSE</td>
                                <td>53.00</td>
                                <td>23.40*</td>
                            </tr>
                            <tr>
                                <td>R¬≤</td>
                                <td>-0.69</td>
                                <td>0.25*</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <p id="metrics-note" class="section-content">
                    Asterisked Random Forest metrics differ from earlier narrative (MAE 3.36, MSE 18.64, R¬≤ 0.41). Final set pending confirmation.
                </p>
            </div>

            <!-- Evaluation Logic -->
            <div class="section">
                <h3 class="section-title">Evaluation & Classification Logic</h3>
                <div class="code-snippet">
<pre><code># Pseudocode for performance classification
for player in current_players:
    y_pred = model.predict(player.features)
    y_true = player.national_team_goals
    if y_true > y_pred:
        player.status = "overperforming"
    elif y_true < y_pred:
        player.status = "underperforming"
    else:
        player.status = "on expectation"
</code></pre>
                </div>
                <p class="section-content">
                    Future refinement: incorporate Poisson or Negative Binomial modeling for goal counts; add per-90 normalization, age curve adjustments, and injury history weighting.
                </p>
            </div>

            <!-- Conclusion -->
            <div class="section">
                <h3 class="section-title">Conclusion</h3>
                <p class="section-content">
                    Combined multivariate reduction (PCA), unsupervised grouping (Clustering), and predictive modeling (CART vs Random Forest) to construct a structured ranking framework for Italian forwards. Ensemble approach (RF) improved error metrics and interpretive robustness‚Äîpending metric reconciliation.
                </p>
                <p class="section-content">
                    Methodological extensibility: integrate expected goals (xG), pressing events, shot quality, and chance creation for richer forward profiling. This analytical stack can generalize to other national squads or club scouting contexts.
                </p>
            </div>

            <!-- Ethical / Assumption Note -->
            <div class="section">
                <h3 class="section-title">Assumptions & Limitations</h3>
                <p class="section-content">
                    Simplification: raw goals treated as holistic performance proxy. Omitted: off-ball movement, pressing intensity, link-up play, defensive contribution. Model variance and negative R¬≤ (CART) highlight need for richer feature engineering. Overperformer designation sensitive to small-sample goal volatility.
                </p>
            </div>
        </div>
    </template>
    <template id="third-project-template" class="detail-template">
        <header class="detail-header">
            <h2 id="detailTitle">Mental Health in Tech ‚Äî OSMI 2016 Analysis</h2>
            <p>From raw survey to actionable HR insights: cleaning, visual exploration, and modeling to understand workplace mental health drivers.</p>
        </header>

        <div class="detail-body">
            <div class="project-meta">
            <span class="tag">Python</span>
            <span class="tag">EDA</span>
            <span class="tag">Visualization</span>
            <span class="tag">Modeling</span>
            <span class="tag">HR Analytics</span>
            </div>

            <!-- Introduction -->
            <div class="section">
            <h3 class="section-title">Introduction</h3>
            <p class="section-content">
                Mental health affects productivity, well‚Äëbeing, and organizational success. Using the OSMI Mental Health in Tech
                Survey 2016, we explore how awareness, resources, and workplace culture relate to employee outcomes to inform HR policy.
            </p>
            <ul class="section-content" style="margin-left:20px;">
                <li><strong>Objectives:</strong> Clean, visualize, and model outcomes tied to workplace factors.</li>
                <li><strong>Audience:</strong> HR and tech leadership.</li>
                <li><strong>Outputs:</strong> Key visuals and concise, actionable recommendations.</li>
            </ul>
            </div>

            <!-- Data Cleaning -->
            <div class="section">
            <h3 class="section-title">Data Cleaning</h3>
            <p class="section-content">
                Starting from 1,433 rows √ó 63 columns, we addressed high missingness, conditional questions, inconsistent formats, and redundant fields.
            </p>

            <div class="detail-card">
                <h4>Handling Missingness</h4>
                <p>
                ‚Ä¢ Dropped columns &gt;50% missing (resources/impacts).<br>
                ‚Ä¢ Removed 287 rows with NA in employer mental health benefits to unlock dependent workplace fields (size, tech org, formal discussion, anonymity, resources, leave ease, perceived consequences, comfort levels).<br>
                ‚Ä¢ Dropped NA rows for ‚Äúunsupportive/badly handled response‚Äù.<br>
                ‚Ä¢ Set conditional NA to ‚ÄúNot Applicable‚Äù (US state work/live; diagnosis-related prompts).
                </p>
            </div>

            <div class="detail-card">
                <h4>Standardization & Redundancy</h4>
                <p>
                ‚Ä¢ Gender normalized to {Male, Female, Other}.<br>
                ‚Ä¢ Removed ‚ÄúAre you self‚Äëemployed?‚Äù and ‚ÄúDo you have previous employers?‚Äù (uninformative).<br>
                ‚Ä¢ Corrected age outliers (323‚Üí32; 3‚Üí30; 99‚Üí30).
                </p>
            </div>

            <div class="badge-row">
                <span class="perf-badge">Initial: 1433 √ó 63</span>
                <span class="perf-badge">Post drops: 1015 √ó 52</span>
                <span class="perf-badge">Final: 976 √ó 50</span>
            </div>

            </div>

            <!-- Data Visualization (high-impact only) -->
            <div class="section">
            <h3 class="section-title">Data Visualization</h3>
            <p class="section-content">
                Core patterns: prevalence by disorder, gender differences, and geographic spread. Respondents are largely 25‚Äì40 and US-based; concerns about stigma and negative consequences are prominent.
            </p>

            <figure class="figure-block">
                <img src="common.png" alt="Most common mental health disorders">
                <figcaption>Disorder prevalence ‚Äî Anxiety and Mood disorders dominate across respondents</figcaption>
            </figure>

            <figure class="figure-block">
                <img src="mhdgender.png" alt="Disorder distribution by gender">
                <figcaption>Disorders by gender ‚Äî differences across Male, Female, and Other categories</figcaption>
            </figure>

            <figure class="figure-block">
                <img src="map2.png" alt="Most common disorders by country">
                <figcaption>Geography ‚Äî Anxiety prevalent across Europe/Canada/Russia/Asia; Mood disorders in US/UK/Chile/Australia; ADHD notable in Denmark</figcaption>
            </figure>
            </div>

            <!-- Modeling -->
            <div class="section">
            <h3 class="section-title">Modeling</h3>
            <p class="section-content">
                Target: presence of mental health disorder (three outcomes). Categorical features one‚Äëhot encoded. Models compared:
                Random Forest, Logistic Regression, Gradient Boosting (GBM), and Decision Tree.
            </p>

            <div class="detail-card">
                <h4>Random Forest (best performer)</h4>
                <p>
                n_estimators=200; max_depth=7; min_samples_leaf=5. Test accuracy: 64%. Handles non‚Äëlinear interactions and provides feature importance.
                Struggled with ‚ÄúMaybe‚Äù class, indicating ambiguity is harder to learn.
                </p>
            </div>
            <div class="detail-card">
                <h4>Logistic Regression</h4>
                <p>
                C=1.5; max_iter=1000. Test accuracy: 53%. Linear decision boundary limits performance on complex relationships.
                </p>
            </div>
            <div class="detail-card">
                <h4>Gradient Boosting (GBM)</h4>
                <p>
                n_estimators=100; learning_rate=0.001; randomized depth to curb overfitting. Test accuracy: 62%. Sequential nature increases tuning sensitivity.
                </p>
            </div>
            <div class="detail-card">
                <h4>Decision Tree</h4>
                <p>
                max_depth=3. Test accuracy: 64%. Interpretable, but limited on complex, non‚Äëlinear patterns and ‚ÄúMaybe‚Äù class.
                </p>
            </div>

            <div class="metrics-table-wrapper">
                <table class="model-metrics" aria-label="Model Performance Comparison">
                <thead>
                    <tr>
                    <th>Model</th>
                    <th>Train Accuracy</th>
                    <th>Test Accuracy</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>Random Forest</td><td>70%</td><td>64%</td></tr>
                    <tr><td>Logistic Regression</td><td>71%</td><td>53%</td></tr>
                    <tr><td>Gradient Boosting</td><td>64%</td><td>62%</td></tr>
                    <tr><td>Decision Tree</td><td>65%</td><td>64%</td></tr>
                </tbody>
                </table>
            </div>

            <figure class="figure-block">
                <img src="important.png" alt="Top 10 most important features in Random Forest">
                <figcaption>Feature importance ‚Äî treatment seeking, family history, workplace response quality, stigma perceptions, and benefits rank highest</figcaption>
            </figure>

            <figure class="figure-block">
                <img src="rfoutput.png" alt="Random Forest first decision tree">
                <figcaption>Random Forest ‚Äî representative tree highlighting primary split logic</figcaption>
            </figure>
            </div>

            <!-- Conclusions & Recommendations -->
            <div class="section">
            <h3 class="section-title">Conclusions & Recommendations</h3>
            <p class="section-content">
                Random Forest balances interpretability and accuracy for this dataset. Key drivers: prior professional treatment,
                family history, workplace handling of MH issues, stigma concerns, and benefits availability.
            </p>
            <ul class="section-content" style="margin-left:20px;">
                <li><strong>Awareness & stigma reduction:</strong> Normalize MH conversations; consider ‚Äúmental health ambassadors‚Äù.</li>
                <li><strong>Accessible resources:</strong> Ensure coverage and confidential counseling pathways.</li>
                <li><strong>Supportive environment:</strong> Protect anonymity; manager training; family‚Äëinclusive ‚Äúhumanizing the workplace‚Äù events.</li>
                <li><strong>Work‚Äëlife balance:</strong> Flexible arrangements to mitigate stress.</li>
                <li><strong>Continuous improvement:</strong> Ongoing feedback loops using data to refine MH support.</li>
            </ul>
            </div>

            <!-- Assumptions & Limitations -->
            <div class="section">
            <h3 class="section-title">Assumptions & Limitations</h3>
            <p class="section-content">
                Self‚Äëreport bias; conditional question structure; simplified gender grouping; single‚Äëyear scope; ‚ÄúMaybe‚Äù class ambiguity.
            </p>
            </div>
        </div>
        </template>

    <!-- New template: Pandoro Gate NLP Analysis -->
    <template id="pandoro-gate-nlp-template" class="detail-template">
        <header class="detail-header">
            <h2 id="detailTitle">Pandoro Gate NLP Analysis</h2>
            <p>An in-depth analysis of public opinion on social media surrounding the "Pandoro Gate" scandal, using Natural Language Processing to extract sentiment and key discussion topics.</p>
        </header>
        <div class="detail-body">
            <div class="project-meta">
                <span class="tag">Python</span>
                <span class="tag">NLP</span>
                <span class="tag">Sentiment Analysis</span>
                <span class="tag">Topic Modeling</span>
                <span class="tag">LDA</span>
                <span class="tag">Social Media Analysis</span>
            </div>

            <div class="section">
                <h3 class="section-title">Introduction</h3>
                <p class="section-content">
                    The "Pandoro Gate" scandal involving Chiara Ferragni became a major media event in Italy, sparking intense public debate. This project aims to cut through the noise and quantitatively analyze the public's reaction on social media. By applying NLP techniques to a large dataset of comments, we can uncover the dominant sentiments and the core themes of the conversation.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">The Challenge</h3>
                <p class="section-content">
                    Social media data is inherently unstructured, noisy, and voluminous. The main challenge was to process thousands of comments written in informal language, complete with slang, emojis, and sarcasm, and transform them into structured, analyzable data. The goal was to build a pipeline that could reliably gauge public opinion and identify what aspects of the scandal people were most focused on.
                </p>
            </div>

            <div class="highlight-box">
                <strong>Key Objective:</strong> Move beyond anecdotal evidence and provide a data-driven picture of the public's response to the crisis, identifying key emotional drivers and conversational themes.
            </div>

            <div class="section">
                <h3 class="section-title">Technical Methodology</h3>
                <div class="technical-details">
                    <div class="detail-card">
                        <h4>üìä Data Collection</h4>
                        <p>Comments were scraped from the Instagram posts of Chiara Ferragni, Fedez, and other relevant public figures and news outlets that covered the story.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üßπ Data Preprocessing</h4>
                        <p>A crucial step involving text cleaning: removal of stopwords, punctuation, and URLs; lowercasing; and lemmatization to standardize the text for analysis.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üòÉ Sentiment Analysis</h4>
                        <p>A pre-trained sentiment analysis model was used to classify each comment as positive, negative, or neutral, providing a high-level view of the overall emotional tone.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üîç Topic Modeling (LDA)</h4>
                        <p>Latent Dirichlet Allocation (LDA) was applied to the corpus of comments to discover abstract topics and the key themes of discussion within the conversation.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h3 class="section-title">Key Findings</h3>
                <p class="section-content">
                    The analysis of the social media comments revealed several clear patterns:
                </p>
                <div class="insight-box">
                    <strong>Overwhelmingly Negative Sentiment:</strong> The vast majority of comments expressed negative sentiment towards Chiara Ferragni, indicating significant public disapproval.
                </div>
                <p class="section-content">
                    The main topics identified through LDA revolved around:
                </p>
                <ul class="section-content" style="margin-left:20px;">
                    <li><b>Deception and Trust:</b> Words like "scam," "lies," and "trust" were prominent, showing a focus on the perceived dishonesty of the affair.</li>
                    <li><b>Charity and Money:</b> A significant portion of the conversation centered on the themes of "charity," "money," and "donations," questioning the commercial nature of the initiative.</li>
                    <li><b>Apology and Responsibility:</b> The apology video was a major topic, with discussions around its sincerity and the legal consequences ("fine," "investigation").</li>
                    <li><b>Brand Image:</b> The impact on Ferragni's brand and her role as an influencer was a recurring theme.</li>
                </ul>
            </div>

            <div class="section">
                <h3 class="section-title">Conclusion</h3>
                <p class="section-content">
                    This NLP analysis provided a structured and quantitative view of the public's reaction to the Pandoro Gate scandal. The findings confirm a significant negative shift in public perception, driven by feelings of betrayal and mistrust. The project demonstrates the power of NLP to distill meaningful insights from vast amounts of unstructured social media data, offering a valuable tool for crisis management and brand reputation analysis.
                </p>
            </div>

            <a href="https://github.com/Filippo2605/Pandoro-Gate-NLP-analysis"
               class="github-link" target="_blank" rel="noopener">
               <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true">
                   <path d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"/>
               </svg>
               View Project on GitHub
            </a>
        </div>
    </template>

    <!-- New template: Customer Churn Prediction -->
    <template id="customer-churn-template" class="detail-template">
        <header class="detail-header">
            <h2 id="detailTitle">Customer Churn Prediction</h2>
            <p>A machine learning project focused on predicting customer churn for a telecommunications company, comparing multiple classification models to find the most effective solution.</p>
        </header>
        <div class="detail-body">
            <div class="project-meta">
                <span class="tag">Python</span>
                <span class="tag">Scikit-learn</span>
                <span class="tag">Machine Learning</span>
                <span class="tag">Classification</span>
                <span class="tag">EDA</span>
                <span class="tag">Logistic Regression</span>
                <span class="tag">SVM</span>
                <span class="tag">Random Forest</span>
            </div>

            <div class="section">
                <h3 class="section-title">Introduction</h3>
                <p class="section-content">
                    Customer churn is a critical metric for subscription-based businesses like telecommunications companies. Acquiring new customers is far more expensive than retaining existing ones. This project tackles the churn problem by building a predictive model that can identify customers who are likely to cancel their service. The goal is to provide the business with actionable insights to proactively engage at-risk customers with targeted retention campaigns.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">Data Exploration and Preprocessing</h3>
                <p class="section-content">
                    The project started with a comprehensive Exploratory Data Analysis (EDA) of the telecom customer dataset. Key insights from the EDA showed that churn was significantly influenced by factors like:
                </p>
                <ul class="section-content" style="margin-left:20px;">
                    <li><b>Contract Type:</b> Customers on month-to-month contracts were much more likely to churn.</li>
                    <li><b>Tenure:</b> New customers (low tenure) had a higher churn rate.</li>
                    <li><b>Online Security and Tech Support:</b> Customers without these services were more likely to leave.</li>
                    <li><b>Payment Method:</b> Customers paying by electronic check had a higher churn rate.</li>
                </ul>
                <p class="section-content">
                    Data preprocessing involved handling categorical variables through one-hot encoding and scaling numerical features using `StandardScaler` to prepare the data for various machine learning models.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">Modeling and Evaluation</h3>
                <p class="section-content">
                    Several classification models were trained and evaluated to find the best predictor of customer churn. The models included:
                </p>
                <div class="technical-details">
                    <div class="detail-card">
                        <h4>Logistic Regression</h4>
                        <p>A baseline model that provides a good starting point due to its interpretability.</p>
                    </div>
                    <div class="detail-card">
                        <h4>Support Vector Machine (SVM)</h4>
                        <p>A powerful model that can find complex relationships in the data.</p>
                    </div>
                    <div class="detail-card">
                        <h4>Decision Tree</h4>
                        <p>A simple, interpretable model that visualizes the decision-making process.</p>
                    </div>
                    <div class="detail-card">
                        <h4>Random Forest</h4>
                        <p>An ensemble model that combines multiple decision trees to improve accuracy and reduce overfitting.</p>
                    </div>
                </div>
                <p class="section-content">
                    The models were evaluated based on accuracy, precision, recall, and F1-score. The Random Forest classifier emerged as the top-performing model.
                </p>
                <div class="metrics-table-wrapper">
                    <table class="model-metrics">
                        <thead>
                            <tr>
                                <th>Model</th>
                                <th>Accuracy</th>
                                <th>Precision</th>
                                <th>Recall</th>
                                <th>F1-Score</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Logistic Regression</td>
                                <td>80.4%</td>
                                <td>65.9%</td>
                                <td>54.9%</td>
                                <td>59.9%</td>
                            </tr>
                            <tr>
                                <td>SVM</td>
                                <td>79.6%</td>
                                <td>64.0%</td>
                                <td>51.5%</td>
                                <td>57.1%</td>
                            </tr>
                            <tr>
                                <td>Decision Tree</td>
                                <td>72.8%</td>
                                <td>48.8%</td>
                                <td>50.0%</td>
                                <td>49.4%</td>
                            </tr>
                            <tr>
                                <td><b>Random Forest</b></td>
                                <td><b>79.2%</b></td>
                                <td><b>64.8%</b></td>
                                <td><b>47.0%</b></td>
                                <td><b>54.5%</b></td>
                            </tr>
                        </tbody>
                    </table>
                </div>
            </div>

            <strong>Top Predictors:</strong> `TotalCharges`, `MonthlyCharges`, and `tenure`. This confirms the intuition that financial aspects and customer loyalty are the primary drivers of churn.
            <br>
            <div class="section" style="margin-top: 20px;">
                <h3 class="section-title">Conclusion</h3>
                <p class="section-content">
                    This project successfully developed a machine learning model capable of predicting customer churn with reasonable accuracy. The Random Forest model proved to be the most effective, and its feature importance analysis provided valuable insights into the key drivers of churn.
                </p>
                <div class="insight-box">
                    <strong>Business Impact:</strong> By deploying this model, a telecommunications company can identify at-risk customers in advance and target them with personalized offers, loyalty programs, or improved customer service, ultimately reducing churn and increasing profitability.
                </div>
            </div>
        </div>
    </template>

    <!-- New template: Automated Journalism -->
    <template id="automated-journalism-template" class="detail-template">
        <header class="detail-header">
            <h2 id="detailTitle">Automated Journalism with NLP and Generative AI</h2>
            <p>A proof-of-concept system that leverages Large Language Models (LLMs) and prompt engineering to automatically generate journalistic articles from structured data sources.</p>
        </header>
        <div class="detail-body">
            <div class="project-meta">
                <span class="tag">Python</span>
                <span class="tag">LangChain</span>
                <span class="tag">LLMs</span>
                <span class="tag">Prompt Engineering</span>
                <span class="tag">NLP</span>
                <span class="tag">Streamlit</span>
                <span class="tag">Generative AI</span>
            </div>

            <div class="section">
                <h3 class="section-title">The Problem</h3>
                <p class="section-content">
                    Journalists often spend significant time writing formulaic, data-driven articles, such as financial earnings reports, sports game summaries, or election results. While essential, this repetitive work consumes valuable time that could be spent on in-depth investigative journalism. The challenge is to automate the creation of these articles while maintaining accuracy, adhering to a specific journalistic style, and allowing for human oversight.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">The Solution: An AI-Powered Pipeline</h3>
                <p class="section-content">
                    This project implements a pipeline that transforms structured data into well-written journalistic articles. It uses the power of Large Language Models (LLMs) orchestrated by the LangChain framework, with a user-friendly interface built in Streamlit.
                </p>
            </div>

            <div class="highlight-box">
                <strong>Core Principle:</strong> The system is designed as a "human-in-the-loop" tool. It doesn't replace journalists but acts as a powerful assistant, generating first drafts that a human editor can quickly refine and publish.
            </div>

            <div class="section">
                <h3 class="section-title">Technical Architecture</h3>
                <div class="technical-details">
                    <div class="detail-card">
                        <h4>üìä Data Input</h4>
                        <p>The system accepts structured data in formats like JSON or CSV. This could be anything from a company's quarterly financial results to the box score of a basketball game.</p>
                    </div>
                    <div class="detail-card">
                        <h4>‚úçÔ∏è Prompt Engineering</h4>
                        <p>A sophisticated prompt template is the core of the system. It instructs the LLM on the desired tone, style, length, and structure of the article, with placeholders for the input data.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üîó LangChain Orchestration</h4>
                        <p>LangChain is used to manage the workflow. It dynamically populates the prompt template with the provided data and handles the communication with the LLM API.</p>
                    </div>
                    <div class="detail-card">
                        <h4>ü§ñ Article Generation</h4>
                        <p>The populated prompt is sent to an LLM (e.g., GPT-3.5/4), which generates a coherent, context-aware article based on the instructions and data.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h3 class="section-title">Interactive Interface with Streamlit</h3>
                <p class="section-content">
                    A simple web application built with Streamlit provides the user interface. It allows a journalist to:
                </p>
                <ul class="section-content" style="margin-left:20px;">
                    <li>Upload a data file (e.g., a CSV of financial data).</li>
                    <li>Select generation parameters, such as the desired tone (e.g., "neutral," "optimistic," "critical").</li>
                    <li>Trigger the article generation process with a single click.</li>
                    <li>View the generated article and copy it for further editing in their preferred word processor.</li>
                </ul>
            </div>

            <div class="insight-box">
                <strong>The Power of Prompting:</strong> The quality of the output is highly dependent on the quality of the prompt. This project involved extensive experimentation to create a robust prompt that could handle different types of data and produce consistently high-quality articles.
            </div>

            <div class="section">
                <h3 class="section-title">Conclusion and Future Work</h3>
                <p class="section-content">
                    This project successfully demonstrates the feasibility of using Generative AI to automate the creation of data-driven journalistic content. It serves as a valuable proof-of-concept for newsrooms looking to increase efficiency and free up journalists for more creative and impactful work.
                </p>
                <p class="section-content">
                    Future enhancements could include direct integration with CMS platforms, automated fact-checking against multiple sources, and the ability to generate articles in different languages.
                </p>
            </div>
        </div>
    </template>

            <!-- Additional future project cards can go here -->
        </section>
    </main>         
    </template>

            <!-- Additional future project cards can go here -->
        </section>
    </main>

    <!-- Overlay for Detailed View -->
    <div class="detail-overlay" id="detailOverlay" aria-hidden="true">
        <div class="detail-inner" role="dialog" aria-modal="true" aria-labelledby="detailTitle">
            <button class="close-btn" type="button" aria-label="Close project details" id="closeOverlay">
                <i class="fa-solid fa-xmark"></i>
            </button>
            <!-- Dynamic content will be injected here -->
            <div id="detailContent"></div>
        </div>
    </div>

    <!-- Hidden template holding full project HTML (original content preserved) -->
    <template id="linkedin-scraper-template" class="detail-template">
        <header class="detail-header">
            <h2 id="detailTitle">LinkedIn Comment Scraper</h2>
            <p>Automated extraction of dynamic LinkedIn comment threads for structured analysis and downstream NLP enrichment.</p>
        </header>
        <div class="detail-body">
            <div class="project-meta">
                <span class="tag">Python</span>
                <span class="tag">Selenium</span>
                <span class="tag">Web Scraping</span>
                <span class="tag">Automation</span>
            </div>

            <div class="section">
                <p class="section-content">
                    In a world where social media conversations hold immense value for understanding public sentiment, engagement patterns, and community dynamics, I built a tool that bridges the gap between LinkedIn's professional discourse and actionable data insights. This project automates the extraction of comments from LinkedIn posts, transforming ephemeral conversations into structured data ready for analysis.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">The Challenge</h3>
                <p class="section-content">
                    LinkedIn's dynamic, JavaScript-heavy interface presents unique challenges for data extraction. Unlike static websites, comments load progressively, requiring interaction with the page to reveal the full conversation. The platform's authentication layer and anti-scraping measures add another dimension of complexity. The goal was clear: create a reliable, automated pipeline that could navigate these obstacles while respecting the platform's structure.
                </p>
            </div>

            <div class="highlight-box">
                <strong>Key Insight:</strong> Modern web scraping isn't just about parsing HTML‚Äîit's about simulating human behavior, understanding asynchronous content loading, and building robust systems that can handle the unpredictable nature of dynamic web applications.
            </div>

            <div class="section">
                <h3 class="section-title">Technical Deep Dive</h3>
                <div class="technical-details">
                    <div class="detail-card">
                        <h4>üîê Authentication Layer</h4>
                        <p>Implemented secure credential management with automated login flow using Selenium WebDriver, handling LinkedIn's authentication challenge while maintaining session persistence.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üîÑ Dynamic Content Loading</h4>
                        <p>Engineered an intelligent pagination system that detects and clicks "Load More" buttons recursively, ensuring complete comment extraction regardless of thread length.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üéØ Smart Element Selection</h4>
                        <p>Utilized XPath and CSS selectors to reliably target comment sorting options, switching to "Most Recent" view for chronological data organization.</p>
                    </div>
                    <div class="detail-card">
                        <h4>üíæ Data Preservation</h4>
                        <p>Captured the complete rendered HTML state, creating a snapshot that preserves all loaded comments for offline processing with BeautifulSoup.</p>
                    </div>
                </div>
            </div>

            <div class="section">
                <h3 class="section-title">The Architecture</h3>
                <p class="section-content">
                    The scraper follows a three-stage pipeline architecture:
                </p>
                <div class="highlight-box">
                    <strong>Stage 1: Initialization & Authentication</strong><br>
                    The WebDriver initializes with Microsoft Edge, navigating to LinkedIn's login portal. Credentials are securely injected, and the system waits for successful authentication before proceeding.
                    <br><br>
                    <strong>Stage 2: Navigation & Dynamic Loading</strong><br>
                    Once authenticated, the scraper navigates to the target post URL. It intelligently identifies and interacts with comment sorting menus, then enters a recursive loop to load all hidden comments.
                    <br><br>
                    <strong>Stage 3: Extraction & Persistence</strong><br>
                    With all comments visible, the complete page source is captured and saved as HTML. This decouples scraping from parsing, allowing for flexible downstream analysis.
                </div>
            </div>

            <div class="section">
                <h3 class="section-title">Code Walkthrough</h3>
                <p class="section-content">
                    Here's how the comment loading mechanism works‚Äîthe heart of the automation:
                </p>
                <div class="code-snippet">
<pre><code>
# Recursive comment loading algorithm
while True:
    try:
        load_button = driver.find_element(
            By.XPATH,
            "//button[contains(@aria-label, 'Load more')]"
        )
        driver.execute_script(
            "arguments[0].scrollIntoView();",
            load_button
        )
        load_button.click()
        time.sleep(2)  # Allow content to render
    except:
        break  # No more comments to load
</code></pre>
                </div>
                <p class="section-content">
                    This elegant loop continues until the "Load more" button disappears, indicating all comments are visible. The scroll behavior ensures elements are in the viewport before interaction, preventing common Selenium exceptions.
                </p>
            </div>

            <div class="section">
                <h3 class="section-title">Beyond Basic Scraping</h3>
                <p class="section-content">
                    What makes this project particularly interesting is its extensibility. The saved HTML serves as a foundation for sophisticated analysis:
                </p>
                <ul class="section-content" style="margin-left:20px;">
                    <li><strong>Sentiment Analysis:</strong> Feed comment text into NLP models to gauge audience reaction to posts</li>
                    <li><strong>Network Mapping:</strong> Extract commenter profiles to build engagement networks and identify key influencers</li>
                    <li><strong>Temporal Analysis:</strong> Study comment velocity and timing to understand optimal posting schedules</li>
                    <li><strong>Content Strategy:</strong> Analyze which topics generate the most meaningful discussions</li>
                </ul>
            </div>

            <div class="insight-box">
                <strong>Ethical Consideration:</strong> This project exists in the educational space, designed to understand web automation and data extraction techniques. Real-world applications must respect LinkedIn's Terms of Service, rate limiting, and user privacy. The goal is learning, not exploitation.
            </div>

            <div class="section">
                <h3 class="section-title">What I Learned</h3>
                <p class="section-content">
                    Building this scraper reinforced several key principles that extend beyond just technical implementation. I learned that effective web scraping is as much about understanding human-computer interaction patterns as it is about code. The challenges of timing, state management, and error handling in a dynamic environment taught me to think in terms of systems resilience rather than just functionality.
                </p>
                <p class="section-content">
                    Perhaps most importantly, this project highlighted the importance of separating concerns‚Äîkeeping scraping logic distinct from parsing logic creates more maintainable, flexible systems that can adapt as websites evolve.
                </p>
            </div>

            <a href="https://github.com/Filippo2605/Scraping-Linkedin-Post-comments"
               class="github-link" target="_blank" rel="noopener">
               <svg width="24" height="24" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true">
                   <path d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z"/>
               </svg>
               View Project on GitHub
            </a>
        </div>
    </template>

    <script>
        (function() {
            const overlay = document.getElementById('detailOverlay');
            const detailContent = document.getElementById('detailContent');
            const closeBtn = document.getElementById('closeOverlay');
            let lastFocused = null;

            function openProject(id) {
                const tpl = document.getElementById(id + '-template');
                if (!tpl) return;
                lastFocused = document.activeElement;
                detailContent.innerHTML = '';
                detailContent.appendChild(tpl.content.cloneNode(true));

                overlay.style.display = 'block';
                overlay.setAttribute('aria-hidden', 'false');

                // Delay to ensure injected content is in DOM
                requestAnimationFrame(() => {
                    const focusable = overlay.querySelector('button.close-btn');
                    if (focusable) focusable.focus();
                });

                document.addEventListener('keydown', escHandler);
                trapFocus();
            }

            function closeProject() {
                overlay.style.display = 'none';
                overlay.setAttribute('aria-hidden', 'true');
                detailContent.innerHTML = '';
                document.removeEventListener('keydown', escHandler);
                releaseFocusTrap();
                if (lastFocused) lastFocused.focus();
            }

            function escHandler(e) {
                if (e.key === 'Escape') {
                    closeProject();
                }
            }

            // Simple focus trap
            let focusTrapHandler = null;
            function trapFocus() {
                focusTrapHandler = function(e) {
                    if (!overlay.contains(e.target)) {
                        const first = overlay.querySelector('button.close-btn');
                        if (first) first.focus();
                    }
                };
                document.addEventListener('focusin', focusTrapHandler);
            }
            function releaseFocusTrap() {
                document.removeEventListener('focusin', focusTrapHandler);
                focusTrapHandler = null;
            }

            // Click / keyboard handlers for cards
            document.querySelectorAll('.flashcard').forEach(card => {
                card.addEventListener('click', () => {
                    const id = card.getAttribute('data-project');
                    openProject(id);
                });
                card.addEventListener('keydown', e => {
                    if (e.key === 'Enter' || e.key === ' ') {
                        e.preventDefault();
                        const id = card.getAttribute('data-project');
                        openProject(id);
                    }
                });
            });

            // Close interactions
            closeBtn.addEventListener('click', closeProject);
            overlay.addEventListener('click', e => {
                // Click outside dialog content closes
                const inner = document.querySelector('.detail-inner');
                if (!inner.contains(e.target)) {
                    closeProject();
                }
            });
        })();
    </script>
</body>

</html>
